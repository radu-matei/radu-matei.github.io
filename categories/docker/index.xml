<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Radu Matei - Developer Evangelist</title>
    <link>https://radu-matei.com/categories/docker/index.xml</link>
    <description>Recent content on Radu Matei - Developer Evangelist</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://radu-matei.com/categories/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Jenkins declarative pipelines with Kubernetes </title>
      <link>https://radu-matei.com/blog/kubernetes-jenkins-azure/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/kubernetes-jenkins-azure/</guid>
      <description>

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deploying-jenkins-with-helm&#34;&gt;Deploying Jenkins with Helm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-credentials-for-your-image-repository&#34;&gt;Create credentials for your image repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-jenkinsfile&#34;&gt;The Jenkinsfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-the-jenkinsfile&#34;&gt;Using the Jenkinsfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#investigating-what-actually-happens-in-the-cluster&#34;&gt;Investigating what actually happens in the cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feedback&#34;&gt;Feedback&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In previous articles &lt;a href=&#34;https://radu-matei.com/blog/k8s18-azure/&#34;&gt;we deployed a Kubernetes 1.8 cluster to Azure using acs-engine&lt;/a&gt;, then &lt;a href=&#34;https://radu-matei.com/blog/k8s-helm-draft-azure/&#34;&gt;configured Helm and Draft to simplify testing applications&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this article we will explore how to deploy Jenkins using Helm and how to configure Jenkins declarative pipelines that build containers, push images to an image repository and update Kubernetes deployments.&lt;/p&gt;

&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;

&lt;p&gt;To follow along with this article, &lt;em&gt;you need a Kubernetes cluster&lt;/em&gt; (we will use Kubernetes v1.8.0, but the instructions were also tested with v1.7.0) with Helm installed and a terminal with &lt;code&gt;kubectl&lt;/code&gt; and &lt;code&gt;helm&lt;/code&gt; installed and configured.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://radu-matei.com/blog/k8s-helm-draft-azure&#34;&gt;This article picks up where the last one ended, so you will need a Kubernetes cluster with &lt;code&gt;helm&lt;/code&gt; installed. Here you can find very simple instructions on how to achieve it.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My cluster is deployed into Azure, West Europe, but you can do the exact same steps using the Google Container Engine or your on-prem cluster (note that you will not be given public IP addresses as is the case with Azure or GKE).&lt;/p&gt;

&lt;p&gt;Now to check that everything is configured, verify your cluster information and vesions. This is my starting point:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/kubernetes-jenkins-azure/cluster-info.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;deploying-jenkins-with-helm&#34;&gt;Deploying Jenkins with Helm&lt;/h1&gt;

&lt;p&gt;Using Helm you can easily deploy well-know applications (like Hadoop, Grafana, MongoDB, Redis) easily on your Kubernetes cluster using charts.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Charts are curated application definitions for Kubernetes Helm.&lt;/p&gt;

&lt;p&gt;More information on &lt;a href=&#34;https://github.com/kubernetes/helm&#34;&gt;Helm&lt;/a&gt; and &lt;a href=&#34;https://github.com/kubernetes/charts&#34;&gt;charts&lt;/a&gt; on GitHub&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we search for &lt;a href=&#34;https://github.com/kubernetes/charts/tree/master/stable/jenkins&#34;&gt;Jenkins in the list of stable charts&lt;/a&gt;, we find very clear instructions on how to deploy it.&lt;/p&gt;

&lt;p&gt;A chart is composed of some templates (Kubernetes deployment files) and a file that holds our specific values for Jenkins - Docker image for master and agents, plugins to install, persistent volumes - basically all configurable values we can get for our Jenkins deployment.&lt;/p&gt;

&lt;p&gt;This is the only file we will need to edit ourselves. Below you can find the one I use.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/466ae82b4b269d6bb762b088683bf9e6.js&#34;&gt;&lt;/script&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/charts/tree/master/stable/jenkins&#34;&gt;Here you can find all possible configuration for the values file, adjust it to your specific needs&lt;/a&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note that this verison mounts the &lt;code&gt;/var/run/docker.sock&lt;/code&gt; socket inside the agent pods so we can built Docker images on our agents. There is a debate on wether you want to actually do that (basically you expose the Docker engine of the Kubernetes agent the pod is running inside), so do it at your own risk.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This also installs other plugins - such as Jenkins Blue Ocean.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/charts/blob/master/stable/jenkins/values.yaml&#34;&gt;The default values for Jenkins (that you can find in this repo)&lt;/a&gt; does not expose it, you can use that, but note that some features we will use later (basically &lt;code&gt;docker build&lt;/code&gt; inside the worker pod) will not work.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Get this file locally, then execute:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;helm install --name jenkins -f jenkins-values.yaml stable/jenkins&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After you deploy the chart, you will get instructions on how to get the initial admin password:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/kubernetes-jenkins-azure/instructions.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the initial admin username is &lt;code&gt;admin&lt;/code&gt; and you should probably change it :)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you take a look at the state of your cluster, you can see that &lt;code&gt;helm&lt;/code&gt; deployed &lt;code&gt;jenkins&lt;/code&gt;, which resulted in two services in Kubernetes, one for the master and one for the agents.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/kubernetes-jenkins-azure/deployed.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Using the initial admin password (follow the instructions you had as output from Helm after deploying Jenkins), go to the public IP of your service and login.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can find the command I used to get the initial admin password, but note that it will vary in your case based on the name you provided and the namespace where you deployed Jenkins.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;printf $(kubectl get secret --namespace default jenkins-jenkins -o jsonpath=&amp;quot;{.data.jenkins-admin-password}&amp;quot; | base64 --decode);echo&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now you have deployed an instance of Jenkins on your Kubernetes cluster using Helm, already configured with all plugins you specified in your &lt;code&gt;jenkins-values.yaml&lt;/code&gt; file and with the ability to execute builds on your cluster.&lt;/p&gt;

&lt;h1 id=&#34;create-credentials-for-your-image-repository&#34;&gt;Create credentials for your image repository&lt;/h1&gt;

&lt;p&gt;The goal is to have end to end automatic deployment to our Kubernetes cluster. This means we need to push images to an image repository (like Docker Hub, Azure Container Repository, Google Container Repository) as part of our Jenkins build.&lt;/p&gt;

&lt;p&gt;Since all the repositories need some sort of authentication, we need to create a credential binding in Jenkins so that we don&amp;rsquo;t keep credentials in source control&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Never, ever keep credentials in source control. Or connection strings, or any sort of sensitive information!&lt;/p&gt;

&lt;p&gt;We can keep them as Kuberentes secrets, or as Jenkins secrets. In this case we will use Jenkins secrets, and we will reference them in our Jenkinsfile.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now create new credentials in Jenkins:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Click the &lt;strong&gt;Credentials&lt;/strong&gt; link in the sidebar&lt;/p&gt;

&lt;p&gt;Click on the &lt;strong&gt;Global credentials&lt;/strong&gt; domain&lt;/p&gt;

&lt;p&gt;Click [&lt;strong&gt;Add Credential&lt;/strong&gt;]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://support.cloudbees.com/hc/en-us/articles/203802500-Injecting-Secrets-into-Jenkins-Build-Jobs&#34;&gt;Full Cloudbees article that explains credentials and credential bindings in Jenkins&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/kubernetes-jenkins-azure/credentials.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now that you have the credentials in place (don&amp;rsquo;t forget to also add an intuitive ID for your credentials in the place I left blank!), you can create a new pipeline.&lt;/p&gt;

&lt;h1 id=&#34;the-jenkinsfile&#34;&gt;The Jenkinsfile&lt;/h1&gt;

&lt;p&gt;The initial goal was to create declarative Jenkins pipelines that we can later store in source control. This pipeline describes our build process, and a usual process when we work with Kubernetes is to build a Docker image, push it to a image repository then to some work with &lt;code&gt;kubectl&lt;/code&gt; (like update the image for a deployment), or with &lt;code&gt;helm&lt;/code&gt; (update a chart, or deploy a new one).&lt;/p&gt;

&lt;p&gt;We will now look at how to write the simplest Jenkinsfile that will to exactly that: build and push an image to a repo and do work with &lt;code&gt;kubectl&lt;/code&gt; and &lt;code&gt;helm&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jenkinsci/kubernetes-plugin&#34;&gt;Here you can read all about writing Jenkinsfiles with the Kubernetes plugin for Jenkins&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/376f5a2b042b0df82d7d905c9c6cf8ff.js&#34;&gt;&lt;/script&gt;

&lt;blockquote&gt;
&lt;p&gt;Don&amp;rsquo;t forget to use your credential ID in the Jenkinsfile!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This Jenkinsfile makes use of having multiple containers in the same Kubernetes pod - we will have 3 containers - one based on a Docker image, one based on &lt;code&gt;kubectl&lt;/code&gt; and the last based on &lt;code&gt;helm&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can create your own containers - in this case I used the official one for Docker and the images built by &lt;a href=&#34;https://twitter.com/LachlanEvenson&#34;&gt;Lachlan Evenson&lt;/a&gt;, since are widely used on Docker Hub and I kind of trust Lachlan :)&lt;/p&gt;

&lt;p&gt;Use images from the Internet at your own risk!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note that we are mounting the Docker socket inside our pod so the Docker container has access to the Docker engine - this step is debatable for using in production (but it is arguably better than using Docker-in-Docker - &lt;a href=&#34;https://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/&#34;&gt;read this article&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Since we are already running in the cluster, the other two containers are already authenticated.&lt;/p&gt;

&lt;p&gt;You can test this Jenkinsfile by creating a simple Jenkins pipeline and pasting this Jenkinsfile directly there (ugly, but the easiest way to do it).&lt;/p&gt;

&lt;p&gt;This is part of the output for the Jenkinsfile above. Please note that from within this container you have access to the real cluster!
You might want to take a look at the new 1.8 RBAC features in Kubernetes, but keep in mind that &lt;em&gt;with great power comes great responsibility!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/kubernetes-jenkins-azure/real-cluster.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;using-the-jenkinsfile&#34;&gt;Using the Jenkinsfile&lt;/h1&gt;

&lt;p&gt;Basically, now all you need to do is replace the dummy steps I wrote for each step and you have yourself a fully functional Jenkins pipeline!&lt;/p&gt;

&lt;p&gt;Put it side by side with your code in the repository and take care of it just as you would with your source code!&lt;/p&gt;

&lt;h1 id=&#34;investigating-what-actually-happens-in-the-cluster&#34;&gt;Investigating what actually happens in the cluster&lt;/h1&gt;

&lt;p&gt;We see that the steps in our Jenkinsfile are executed, but let&amp;rsquo;s explore a bit where that really happens.&lt;/p&gt;

&lt;p&gt;Whenever there&amp;rsquo;s a new build, the master will dynamically create agent pods based on your Jenkinsfile. There will always be a &lt;code&gt;jnlp&lt;/code&gt; container there that knows how to connect to the master, among with whatever containers you specify.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see that pod in action:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/kubernetes-jenkins-azure/pod.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here you can see all containers inside the pod (with their image, tag and environment variables).&lt;/p&gt;

&lt;p&gt;The cool thing about this plugin is you only see resources being used (CPU + memory) when there&amp;rsquo;s a build in progress. Once that build is done, your resources are freed:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/kubernetes-jenkins-azure/spike.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The short spike at the end corresponds to a build being executed&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;We deployed Jenkins on our Kubernetes cluster using Helm (in a reproduceable way, you can deploy it again with the same plugins at any time - keep this in a source control as well), then saw how to configure credentials and write Jenkinsfiles in a declarative way and have multiple containers in the agent pod.&lt;/p&gt;

&lt;h1 id=&#34;feedback&#34;&gt;Feedback&lt;/h1&gt;

&lt;p&gt;If you have a better aproach at any of the concepts presented in this article, or have any questions, please use the comments below.&lt;/p&gt;

&lt;p&gt;As always, thanks for reading, and any feedback is highly appreciated :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Hybrid Cluster: A CI/CD Story [Part 1] - Configuring a hybrid swarm mode cluster in Azure with acs-engine</title>
      <link>https://radu-matei.com/blog/hybrid-swarmmode/</link>
      <pubDate>Mon, 03 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/hybrid-swarmmode/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is the first part in our (at least) two parts describing how to get started with a hybrid Docker Swarm Mode cluster. In this first part, we will focus on deploying a hybrid cluster on Azure.&lt;/p&gt;

&lt;p&gt;Now, you can create yourself a hybrid cluster within any private network where you have a Windows Server 2016 with Containers and a Linux machine - it can be locally, with VirtualBox, Hyper-V or VMWare, or it can be on your cloud provider of choice. The simplicity of Docker Swarm allows us to easily create a swarm within minutes of having our VMs deployed.&lt;/p&gt;

&lt;p&gt;Here is a list of resources you might want to get started with before diving into this article:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/swarm/swarm-tutorial/&#34;&gt;Getting started with Swarm Mode and Linux Containers - Docker docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode&#34;&gt;Getting started with Swarm Mode and Windows Containers - Microsoft docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode#linuxwindows-mixed-os-clusters&#34;&gt;Initializing a Linux+Windows mixed-os cluster - Microsoft docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;how-is-this-article-different-compared-to-the-docs-above&#34;&gt;How is this article different compared to the docs above?&lt;/h2&gt;

&lt;p&gt;In this article we will focus on deploying the cluster on Azure programatically, using &lt;a href=&#34;https://github.com/Azure/acs-engine&#34;&gt;acs-engine&lt;/a&gt;, a tool that generates &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-overview&#34;&gt;ARM (Azure Resource Manager) templates&lt;/a&gt; for Docker enabled clusters on Microsoft Azure. It will also deploy all resources necessary for our cluster, like load balancers, configure DNS for masters and agents and scale sets for agents and masters. More on this later.&lt;/p&gt;

&lt;p&gt;While you can &lt;a href=&#34;https://github.com/Azure/acs-engine&#34;&gt;find more information about acs-engine on the GitHub repo&lt;/a&gt;, in short, the tool takes a cluster definition file and outputs ARM templates that can be deployed using the &lt;a href=&#34;https://azure.github.io/projects/clis/&#34;&gt;various Azure command-line interfaces&lt;/a&gt; like Azure CLI 2.0 or Azure PowerShell.&lt;/p&gt;

&lt;h2 id=&#34;getting-started-prerequisites&#34;&gt;Getting started - prerequisites&lt;/h2&gt;

&lt;p&gt;This article will continue under the assumption that you have an active Azure subscription. If you don&amp;rsquo;t, there are various ways to get a free subscription, like &lt;a href=&#34;https://www.visualstudio.com/dev-essentials/&#34;&gt;Visual Studio Dev Essentials&lt;/a&gt; (see &lt;a href=&#34;https://github.com/awesome-opening-opportunities/technical-documentation/blob/master/docs/vs-dev-essentials.md&#34;&gt;this link on how to activate your free monthly $25&lt;/a&gt;), or a &lt;a href=&#34;https://azure.microsoft.com/en-us/free/&#34;&gt;free trial&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Before you get started, there is a &lt;a href=&#34;https://channel9.msdn.com/Events/DXPortugal/OSCAMP-Open-Source-Software-powered-by-Bright-Pixel/The-Hybrid-Swarm-Running-Windows-and-Linux-Apps-in-one-Docker-Cluster&#34;&gt;great talk by Docker Developer Advocate and Microsoft MVP Elton Stoneman titled: The Hybrid Swarm: Running Windows and Linux Apps in one Docker Cluster&lt;/a&gt; where he talks about the concepts involved in having a hybrid swarm cluster and that I highly recommend.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;understanding-all-types-of-containers&#34;&gt;Understanding all types of containers&lt;/h2&gt;

&lt;p&gt;First, there are Linux containers. They have been around for a while now (no, Docker did not invent them) and Docker created awesome tooling and integrations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/journey.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/allthingscontainer/2016/10/14/why-containers/&#34;&gt;Photo credits to Bruno Terkaly, from this article&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Linux containers use the host kernel to run &amp;ldquo;containerized&amp;rdquo; workloads - that is execute the process inside the container using Linux kernel features like cgroups and namespaces. Of course, to run Linux containers you need a Linux kernel - this hasn&amp;rsquo;t changed and will not change any time soon.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/&#34;&gt;When we talk about the Windows ecosystem&lt;/a&gt;, we have Windows Server Containers and Hyper-V Containers.&lt;/p&gt;

&lt;p&gt;Windows Server Containers, much like Linux containers, share the kernel with the host and other containers. &amp;ldquo;These containers do not provide a hostile security boundary and should not be used to isolate untrusted code.&amp;rdquo; (&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/&#34;&gt;source - Microsoft docs&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Hyper-V Containers - &amp;ldquo;expands on the isolation provided by Windows Server Containers by running each container in a highly optimized virtual machine. In this configuration, the kernel of the container host is not shared with other containers on the same host. These containers are designed for hostile multitenant hosting with the same security assurances of a virtual machine. Since these containers do not share the kernel with the host or other containers on the host, they can run kernels with different versions and configurations.&amp;rdquo; (&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/&#34;&gt;source - Microsoft docs&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;However, there&amp;rsquo;s a twist: announced at DockerCon 2017, you will be able to run Linux containers on Windows hosts using Hyper-V Isolation&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/win-linux-containers.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/finally-linux-containers-really-will-run-windows-linuxkit/&#34;&gt;Image from The New Stack&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is all possible through the new &lt;a href=&#34;https://github.com/linuxkit/linuxkit&#34;&gt;LinuxKit project&lt;/a&gt;, but more on this on a separate article in the future.&lt;/p&gt;

&lt;p&gt;After we deploy our cluster, we will be able to deploy all types of containers described above.&lt;/p&gt;

&lt;h2 id=&#34;the-acs-engine-cluster-definition&#34;&gt;The acs-engine cluster definition&lt;/h2&gt;

&lt;p&gt;As said earlier, we will use a JSON cluster definition file to, well, define our cluster.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/f610287201e4c08eb2e69eb5ebd02b2f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;This is a pretty standard cluster definition file for acs-engine, except for the addition of &lt;code&gt;windowspool&lt;/code&gt;, a pool of Windows Server agents in our cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can find &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/master/docs/clusterdefinition.md&#34;&gt;in-depth documentation for the cluster definition on the acs-engine GitHub repo here.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;From the definition file, we see that we have a Swarm Mode cluster, with 3 Linux masters, 3 Linux agents and 3 Windows Server 2016 agents. Before we can use this definition file, we need to add the required values for &lt;code&gt;dnxPrefix&lt;/code&gt; for the masters, Linux and Windows agents.&lt;/p&gt;

&lt;p&gt;You must also provide a username and public SSH key for the Linux VMs and a username and password for the Windows VMs, and you can change the default number of 3 for the agent and master count.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/acs-swarmmode.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Compared to the image above, there is an additional VM Scale Set with the Windows agents. All VMs are in the same VNET, with the masters on a private subnet. All VMs are fully accessible to each other.&lt;/p&gt;

&lt;h2 id=&#34;deploying-the-cluster-to-azure&#34;&gt;Deploying the cluster to Azure&lt;/h2&gt;

&lt;p&gt;So far we only have a cluster definition (with values for FQDN, usernames and passwords). Before we can actually deploy, we need to generate the ARM templates using acs-engine.&lt;/p&gt;

&lt;p&gt;In order to do this, we will use the &lt;code&gt;acs-engine&lt;/code&gt; tool. After we have the ARM template, we will use the &lt;code&gt;az&lt;/code&gt; CLI to deploy them. You could install these either locally, or within containers, but the easiest way to do it is to use the &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cloud-shell/overview&#34;&gt;Azure Cloud Shell&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/cloud-shell.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;List of tools and languages supported in the Azure Cloud Shell&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Log into &lt;a href=&#34;https://portal.azure.com&#34;&gt;portal.azure.com&lt;/a&gt; and request a cloud shell. You should see something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/portal-shell.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now we should &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/master/docs/acsengine.md#downloading-and-building-acs-engine&#34;&gt;follow the instructions in the acs-engine documentation&lt;/a&gt; and install acs-engine in the Azure Cloud Shell.&lt;/p&gt;

&lt;p&gt;First, we need to create a new directory called &lt;code&gt;go&lt;/code&gt; and set it as &lt;code&gt;GOPATH&lt;/code&gt;: &lt;code&gt;mkdir go&lt;/code&gt; and &lt;code&gt;export GOPATH=/home/{yourusername}/go&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Then, we need to download the package for acs-engine: &lt;code&gt;go get github.com/Azure/acs-engine&lt;/code&gt;, then navigate to the source of the package and build it: &lt;code&gt;go build&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Then, we add the &lt;code&gt;bin&lt;/code&gt; folder from the &lt;code&gt;go&lt;/code&gt; directory in the path: &lt;code&gt;export PATH=$PATH:/home/{yourusername}/go/bin&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Now you should be able to execute &lt;code&gt;acs-engine&lt;/code&gt; from any directory:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/acs-engine.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s create the ARM templates we will deploy: in a new directory, download the gist with the initial cluster definition (the gist file from above). You can either copy it yourself, or &lt;code&gt;wget&lt;/code&gt; the file:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;wget https://gist.githubusercontent.com/radu-matei/f610287201e4c08eb2e69eb5ebd02b2f/raw/d6a30f867b09d4baa64f78d2499a154096d053e2/swarmmode-hybrid.json&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After you edit the file with your values, generate the ARM templates using &lt;code&gt;acs-engine generate swarmmode-hybrid.json&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/acs-engine-generate.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will create an &lt;code&gt;_output&lt;/code&gt; directory that will contain the ARM template tht we will use for the deployment.&lt;/p&gt;

&lt;p&gt;First of all, we will create a new resource group: &lt;code&gt;az group create --location westeurope --name your-resourcegroup-name&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you should choose the region closest to your location.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then, using the generated files &lt;code&gt;azuredeploy.json&lt;/code&gt; and &lt;code&gt;azuredeploy.parameters.json&lt;/code&gt;, create a new deployment using the &lt;code&gt;az&lt;/code&gt; command-line interface:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;az group deployment create --name hybrid-swarmmode-deployment --resource-group {your-resource-group} --template-file azuredeploy.json  --parameters azuredeploy.parameters.json&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you can also use a local installation of &lt;code&gt;az&lt;/code&gt;, or in a container, or any method of deploying ARM templates.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After the deployment started, here is how the resource group should look like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/rg.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice the resources created in the resource group:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;3 public IPs for masters, Linux agents and Windows agents&lt;/li&gt;
&lt;li&gt;load balancers for masters, Linux agents and Windows agents&lt;/li&gt;
&lt;li&gt;VM scale sets for the agents and availability sets&lt;/li&gt;
&lt;li&gt;network interfaces and OS disks for the masters&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;connecting-to-the-cluster&#34;&gt;Connecting to the cluster&lt;/h2&gt;

&lt;p&gt;After the deployment succeeds, you are now ready to connect to the master. You will SSH into the masters using the user and SSH key you setup in the cluster definition file. The 3 FQDNs will have the following template:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;{yourfqdnname}.{azurelocation}.cloudapp.azure.com&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Each master can be publicly accessed using the FQDN and one of the ports (2200..220x) (So you will access the first master on 2200, the second master on 2201 and so on.). For example, to SSH into the first master, use the following:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh -i path-to-private-key azureuser@{yourfqdn}.{azurelocation}.cloudapp.azure.com -p 2200&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then, if you list all nodes in the cluster you might first see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/docker-node-ls.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This means we only see the 3 masters and the 3 Linux agents. This means that even though the Windows nodes were deployed, they did not join the swarm.&lt;/p&gt;

&lt;p&gt;A very quick solution is to reimage the Windows agents. This means restoring them to the initial state and executing all scripts that were executed when initializing the cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A very probable cause of this could be that &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/dd2edf94e182dd9006ddf3fa8f8388b4e5a1eed5/parts/Install-ContainerHost-And-Join-Swarm.ps1&#34;&gt;the script that joins the Windows agents to the cluster&lt;/a&gt; might get executed before the masters actually start.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After reimaging or restarting the VMs, your cluster should look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/node-ls-wc.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now you have a full hybrid Swarm Mode cluster, with some Windows agents, as well as Linux ones:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/node-inspect.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;deploying-services-to-the-cluster&#34;&gt;Deploying services to the cluster&lt;/h2&gt;

&lt;p&gt;From now on, you can treat this cluster as any other Docker Swarm Mode cluster: with the single mention that you cannot run Linux containers on Windows and Windows containers on Linux. This means that when starting services, we need to put some restrictions in place.&lt;/p&gt;

&lt;p&gt;We will deploy a simple Python web application on Linux that will use a Redis data store that we will run on Windows.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft-dx/docker-lab/tree/master/apps/python-redis&#34;&gt;The Python application can be found here&lt;/a&gt; and is very similar to the &lt;a href=&#34;https://docs.docker.com/compose/gettingstarted/&#34;&gt;Docker Compose one from the Official Docker Docs&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/7543e906e3633075cd32231e46628bf1.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The most important thing to notice in the stack file is the deployment constraint on the node operating system. As stated earlier, this is very important in the stack file as a Linux service will not run in a Windows host and vice-versa.&lt;/p&gt;

&lt;p&gt;You can see that the &lt;code&gt;redis&lt;/code&gt; service is based on the Windows version of Redis (not something that you would use in production, here just for showcase) and is based on the Nano Server image.&lt;/p&gt;

&lt;p&gt;To deploy this on the master, you need the file above. You can copy it, or &lt;code&gt;wget&lt;/code&gt; it directly: &lt;code&gt;wget https://gist.githubusercontent.com/radu-matei/7543e906e3633075cd32231e46628bf1/raw/f5e06e372c9a5c57f555e8580eee1c1a5ccb635e/hybrid-stack.yml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then, you need to &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/stack_deploy/&#34;&gt;create a new stack deployment&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker stack deploy --compose-file hybrid-stack.yml python-redis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/stack-deploy.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will create two new services, the web and Redis ones, and a new network for them.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/service-ls.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/library/redis/&#34;&gt;Since the Nanoserver Redis image&lt;/a&gt; is around 340 MB, it will take a little to pull it, then start a container.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now since the application that exposes ports is the one running on a Linux node (the web application), we will access it on the port 80 (the one exposed) of the Linux agent FQDN:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/running.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article we saw how to deploy a hybrid Swarm Mode cluster on Azure using acs-engine and how to deploy a mixed-OS containerized application on the cluster we created.&lt;/p&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;Next, we will explore how to create a consistent CI/CD story with GitHub and Jenkins (with Linux and Windows slaves that are created dynamically for each build).&lt;/p&gt;

&lt;h2 id=&#34;feedback&#34;&gt;Feedback&lt;/h2&gt;

&lt;p&gt;If you think this article could be better, please provide your feedback in the comments below.&lt;/p&gt;

&lt;h2 id=&#34;thanks-for-reading&#34;&gt;Thanks for reading :)&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Dockerizing an ASP.NET Core application with GitHub, Docker Cloud and Azure</title>
      <link>https://radu-matei.com/blog/aspnet-core-docker-azure/</link>
      <pubDate>Sat, 26 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/aspnet-core-docker-azure/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this article, we will take the simplest ASP.NET Core application, run it with Docker locally, then create Continuous Integration and Continuous Deployment flows using a GitHub repository, Docker Cloud and an Azure virtual machine that will act as a node for Docker Cloud.&lt;/p&gt;

&lt;p&gt;If you don&amp;rsquo;t want to create an ASP.NET Core application but are interested in the CI/CD workflow, or if you already have a GitHub repository with a complete application with a Dockerfile, &lt;a href=&#34;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&#34;&gt;you might want to skip to the part we start creating the CI/CD workflow.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;moving-parts-and-used-components&#34;&gt;Moving parts and used components&lt;/h2&gt;

&lt;p&gt;The main part of a CI/CD workflow like this is the application itself. It can be however complicated, but in this case I want to emphasize the workflow itself and will only build a very simple application with ASP.NET Core.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you can use this article with any single-container application you want to build.&lt;/p&gt;

&lt;p&gt;However, if you want to build multi-container applications, you will most likely need a way to compose and orchestrate those containers. In future articles, we will also deal with multi-container applications, but in this one we will keep things easy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will create a GitHub repository that we will use to create a Docker image and push it to Docker Hub.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker Hub is a cloud-based registry service which allows you to link to code repositories, build your images and test them, stores manually pushed images, and links to Docker Cloud so you can deploy images to your hosts. It provides a centralized resource for container image discovery, distribution and change management, user and team collaboration, and workflow automation throughout the development pipeline.&lt;/p&gt;

&lt;p&gt;More information about Docker Hub on &lt;a href=&#34;https://docs.docker.com/docker-hub/&#34;&gt;the Official Docker Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then, we will configure an Azure VM to be a node for Docker Cloud and Docker Cloud will automatically publish containers to that VM. Then, every time there are changes in the GitHub repository, Docker Cloud will build the image and publish the container again automatically.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;More information about Docker Cloud on &lt;a href=&#34;https://docs.docker.com/docker-cloud/overview/&#34;&gt;the Official Docker Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/ci-cd-workflow.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.docker.com/2016/04/cicd-with-docker-cloud/&#34;&gt;Photo source on the Docker Blog&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;create-a-github-repository&#34;&gt;Create a GitHub repository&lt;/h2&gt;

&lt;p&gt;First, we need a GitHub repository. If you already have a repo with an application you want to use you can do that. However, I will create a new repo and clone it on my computer.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you can follow this article regardless of your computer OS. It can be done with Windows, Linux or macOS.&lt;/p&gt;

&lt;p&gt;In creating this article, I used macOS, with Docker for Mac and Visual Studio Code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/github-new-repo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since this is a .NET Core application, I chose to add a &lt;code&gt;.gitignore&lt;/code&gt; file that will ignore all .NET specific output files after building the application.&lt;/p&gt;

&lt;p&gt;Create the repository, then clone it somewhere locally on your computer. In my case, I would execute &lt;code&gt;git clone https://github.com/radu-matei/aspnet-core-docker-azure&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;creating-the-asp-net-core-application&#34;&gt;Creating the ASP.NET Core application&lt;/h2&gt;

&lt;p&gt;This will be the part with the least focus in this article, since we have covered building ASP.NET Core applications for a while now and you can find a lot resources on this topic, including some on this site.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For ASP.NET Core tutorials, you can &lt;a href=&#34;https://radu-matei.github.io/categories/aspnet-core/&#34;&gt;take a look at some resources on this blog&lt;/a&gt;, consult the &lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/&#34;&gt;official documentation&lt;/a&gt;, or you can watch this &lt;a href=&#34;https://mva.microsoft.com/en-US/training-courses/introduction-to-aspnet-core-10-16841&#34;&gt;Microsoft Virtual Academy course presented by Scott Hanselman and Maria Naggaga&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Basically, we will create the same application as explained in &lt;a href=&#34;https://radu-matei.github.io/blog/aspnet-core-startup/&#34;&gt;this blog post&lt;/a&gt;, but we will build it against .NET Core 1.0.1 (which is the latest stable version at the moment of writing this article).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;While .NET Core 1.0.1 is the latest version at the moment of writing this article, you can also use other versions, since the Docker images are available on Docker Hub.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the folder that was just created from cloning the repository, execute &lt;code&gt;dotnet new&lt;/code&gt; in order to create a new .NET Core application.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/git-clone-dotnet.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now depending on the .NET Core version you have installed on your machine, &lt;code&gt;project.json&lt;/code&gt; will look slightly different:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Microsoft.NETCore.App&amp;quot;: {
  &amp;quot;type&amp;quot;: &amp;quot;platform&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;1.0.1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since &lt;code&gt;1.0.1&lt;/code&gt; is the latest stable version, we will use it as example for this application.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can use any version available on your machine and as image from Microsoft on Docker Hub.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Add the required Kestrel dependency in &lt;code&gt;project.json&lt;/code&gt;, keeping in mind that the version is &lt;code&gt;1.0.1&lt;/code&gt; and respond to any incoming request with a message and the current date and time of the server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    public static void Main(string[] args)
        {
            var host = new WebHostBuilder()
                .UseKestrel()
                .Configure(app =&amp;gt; app.Run(context =&amp;gt; 
                {
                    return context.Response.WriteAsync($&amp;quot;Hello, Universe! It is {DateTime.Now}&amp;quot;);
                }))
                .Build();

            host.Run();
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is the entire ASP.NET Core application we will use for this article.&lt;/p&gt;

&lt;h2 id=&#34;writing-the-dockerfile&#34;&gt;Writing the Dockerfile&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34;&gt;More information on the Dockerfile on the Official Docker Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Basically, the Dockerfile is like a recipe for building container images. It is a script composed of multiple commands executed succesively to create images based on other images.&lt;/p&gt;

&lt;p&gt;You have two options for writing the Dockerfile: you can write it manually, or you can have VS Code write it for you. If you &lt;a href=&#34;https://code.visualstudio.com/Docs/languages/dockerfile&#34;&gt;install the VS Code Docker extension&lt;/a&gt;, press F1 and search for Docker, you should see something similar to:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/vscode-docker.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this case, we will write the Dockerfile manually, mainly because we want to understand all the things involved.&lt;/p&gt;

&lt;p&gt;Create a new file called &lt;code&gt;Dockerfile&lt;/code&gt; (without extension) to the root of the application (in this case in the same folder as &lt;code&gt;project.json&lt;/code&gt; and &lt;code&gt;Program.cs&lt;/code&gt;) with the following content:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM microsoft/dotnet:1.0.1-sdk-projectjson

COPY . /app
WORKDIR /app

RUN [&amp;quot;dotnet&amp;quot;, &amp;quot;restore&amp;quot;]
RUN [&amp;quot;dotnet&amp;quot;, &amp;quot;build&amp;quot;]

EXPOSE 5000/tcp
ENV ASPNETCORE_URLS http://*:5000

ENTRYPOINT [&amp;quot;dotnet&amp;quot;, &amp;quot;run&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The content of the Dockerfile is pretty self-explanatory:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;it gets a base image that has &lt;code&gt;dotnet&lt;/code&gt; installed, the &lt;code&gt;microsoft/dotnet:1.0.1-sdk-projectjson&lt;/code&gt; image&lt;/li&gt;
&lt;li&gt;it copies the source of the application inside the container, in the &lt;code&gt;/app&lt;/code&gt; folder&lt;/li&gt;
&lt;li&gt;it sets the &lt;code&gt;/app&lt;/code&gt; folder as the working folder where the commands will be executed from&lt;/li&gt;
&lt;li&gt;executes &lt;code&gt;dotnet restore&lt;/code&gt; and &lt;code&gt;dotnet build&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;expoes the 5000 port&lt;/li&gt;
&lt;li&gt;sets the environment variable for ASP .NET Core in the container&lt;/li&gt;
&lt;li&gt;when the container starts it will execute the &lt;code&gt;dotnet run&lt;/code&gt; command&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;In this case, we both build and run the application inside the container. In a production environment, we would only use the &lt;code&gt;dotnet runtime&lt;/code&gt; image from Microsoft that is only able to execute applications and not build them. This would result in a much smaller footprint of the image.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;building-the-image&#34;&gt;Building the image&lt;/h2&gt;

&lt;p&gt;At this point, we have configured the application (which wasn&amp;rsquo;t that hard), we have a definition for Docker, our Dockerfile, but we haven&amp;rsquo;t built an image or a container so far.&lt;/p&gt;

&lt;p&gt;The end result is for us to start a container. Every container is built upon an image, that is composed of the application itself and its dependencies.&lt;/p&gt;

&lt;p&gt;To build the image, simply run the following command in the same folder with the Dockerfile:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker build -t aspnet-core-docker-azure&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-build-1.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-build-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can clearly see how each step in the Dockerfile is executed succesively and how at every step an intermediate container gets created. This is done so that if the execution fails at let&amp;rsquo;s say STEP 7, all progress made up to that point doesn&amp;rsquo;t get lost. After every successful step executed, the previous container is removed.&lt;/p&gt;

&lt;p&gt;Running &lt;code&gt;docker images&lt;/code&gt; should show you the newly created image containing your application and its dependencies (among other images that you might have).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-images.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice though that the base for our image also got pulled from Docker Hub - &lt;code&gt;microsoft/dotnet:1.0.1-sdk-projectjson&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;running-a-new-container&#34;&gt;Running a new container&lt;/h2&gt;

&lt;p&gt;Now that we built our image it&amp;rsquo;s time to run a new container based on that image.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker run -d -p 8080:5000 -t aspnet-core-docker-azure&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s examine the aruments passed along the &lt;code&gt;docker run&lt;/code&gt; command:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;-d&lt;/code&gt; - the container will run in &lt;code&gt;detached&lt;/code&gt; mode, so we won&amp;rsquo;t see logs from the container as output&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;-p 8080:5000&lt;/code&gt; - this will map the 5000 port inside the container (that the application is running on&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;remember the Dockerfile) to port 8080 from the host&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;-t&lt;/code&gt; - the tag of the image this container is based on&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This command started our container, so Docker must have executed &lt;code&gt;dotnet run&lt;/code&gt; inside the container (remember the last line in the Dockerfile), so the application should have started.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-run.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The output of this command is the id of the newly created container, so we can verify that the container is running using the &lt;code&gt;docker ps&lt;/code&gt; command:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-ps.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see the id of the container, the image it is based on, the command used as entrypoint and the port mapping: 8080 on the host to 5000 inside the container.&lt;/p&gt;

&lt;p&gt;So if we navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; we should see our application running:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-run-browser.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So far we created a very simple ASP .NET Core application and we ran it locally inside Docker.We  haven&amp;rsquo;t used the GitHub repo, Docker Hub, Docker Cloud or Azure just yet. This is where we start doing so.&lt;/p&gt;

&lt;h2 id=&#34;setup-an-azure-vm-as-node-for-docker-cloud&#34;&gt;Setup an Azure VM as node for Docker Cloud&lt;/h2&gt;

&lt;p&gt;While Docker Cloud allows you to run containers and build images on some free tier servers, you would most likely want to do it on your own machine.&lt;/p&gt;

&lt;p&gt;If you link the Docker Cloud account with your cloud subscription (in this case Azure), you can create nodes and clusters directly from the Docker Cloud portal.&lt;/p&gt;

&lt;p&gt;In this case we will normally create a VM from the Azure Portal (or from any other cloud provider or on-premise) and install the Docker Cloud agent.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-cloud-bring-node.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I created an Ubuntu Server 14.04 VM (at the moment of writing this article, only Ubuntu 14.04 and 15.04 are supported by Docker Cloud).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-create-vm-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After the deployment succeeds, we will need to open some ports on that VM so the Docker Cloud self discovery service can work. &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-nsg-quickstart-portal&#34;&gt;In this article you can see the detalied process on how to open ports for Azure VMs.&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;We recommend you open incoming port 2375 in your firewall for Docker Cloud to communicate with the Docker daemon running in the node. For the overlay network to work, you must open port 6783/tcp and 6783/udp.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You have to find the &lt;code&gt;Network Security Group&lt;/code&gt; tab from the VM settings, then the &lt;code&gt;Network Security Group&lt;/code&gt; tab then the &lt;code&gt;Inbound Security Roules&lt;/code&gt; tab.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-network-security.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As the Docker Cloud documentation states, we should open ports 2375 and 6783/tcp and udp.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-2375.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then do the same for 6783/tcp and 6783/udp, and since this VM will host the running container, I will also open a port for HTTP - which will automatically open port 80.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you plan to run multiple containers at the same time that expose ports on this machine, you should open more ports to be accessible from outside the VM.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I will also setup a DNS name for the VM so that I don&amp;rsquo;t have to remember the IP of the machine:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-vm-dns.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At this point, you should be able to SSH into the machine and install the Docker Cloud agent.&lt;/p&gt;

&lt;p&gt;On macOS, Linux or Bash on Windows, to SSH into a machine:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh user-name@your-machine-dns-or-ip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In my case, I would run
 &lt;code&gt;ssh radu-matei@ubuntu-docker-cloud.westeurope.cloudapp.azure.com&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-vm-ssh.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After this, I could just paste the command that installs the Docker Cloud agent:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;curl -Ls https://get.cloud.docker.com/ | sudo -H sh -s your-unique-hash&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You might still see some Tutum references in the scripts, as this was the name of the company acquired by Docker that initially developed the functionality behind Docker Cloud.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After the command above successfully executed and you refreshed your Docker Cloud tab, you should see your newly created node.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-node.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is all the required setup for a VM to be a Docker Cloud node.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-repository-in-docker-cloud&#34;&gt;Creating a repository in Docker Cloud&lt;/h2&gt;

&lt;p&gt;By now, the GitHub repository with the application should be up to date, since we will use it to create a new Docker Cloud repository that will automatically build images on every git push in the GitHub repo.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-create-repo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;By default, the webhook will be setup for the master branch on every push, but you can also set it up for specific events, like certain releases.&lt;/p&gt;

&lt;p&gt;By default, the newly created image will be public, but you can make it private. Note that you have a limited number of private repositories in the free tier.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-repo-info.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After it was created and Docker Cloud successfully tested the connection with GitHub, we should set the build process so that it uses the node we just provided and not the shared one provided by Docker Cloud:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-repo-build.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you configured automated notifications on Slack, every time there is an event related to the service you are creating, you will have notifications on Slack.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/slack-notifications.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After you click &lt;code&gt;Save and Build&lt;/code&gt; the image building will start on the machine you provided.&lt;/p&gt;

&lt;p&gt;At any time you can see the logs from building the image in the &lt;code&gt;Builds&lt;/code&gt; tab.
&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/build-logs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now if you go to Docker Hub you should see your newly created image.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-service-based-on-the-image-we-created&#34;&gt;Creating a service based on the image we created&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;A service is a group of containers of the same image:tag. Services make it simple to scale your application. With Docker Cloud, you simply drag a slider to change the number of containers in a service.&lt;/p&gt;

&lt;p&gt;Before you can deploy a service in Docker Cloud, you must have at least one node deployed. If you havent done this yet follow the tutorial to deploy a node .&lt;/p&gt;

&lt;p&gt;When you create a service in the Docker Cloud web interface, a wizard walks you through configuring the service in three steps.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Choose a Container Image Images can come from Docker Clouds Jumpstarts library, your personal Docker Hub account or Docker Hubs public index, or from third party registries you connect.&lt;/li&gt;
&lt;li&gt;Configure the Service From here, give the service a name, set the initial number of containers, expose/publish ports, modify the run command or entrypoint, set memory and CPU limits.&lt;/li&gt;
&lt;li&gt;Set Environment variables Set the edit environment variables and link your service to other existing services in Docker Cloud.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More on Docker Cloud services on &lt;a href=&#34;https://docs.docker.com/docker-cloud/getting-started/your_first_service/&#34;&gt;the Official Docker Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will create a service based on the image we just created.&lt;/p&gt;

&lt;p&gt;The only custom settings will be to enable the &lt;code&gt;AUTOREDEPLOY&lt;/code&gt; option and to specify the port to be 80 on the machine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/autoredeploy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/port.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After hitting the create, it will create the service and already start a container based on this service.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/service-starting.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If we go to the containers tab, we can see the container running.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/containers.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;testing-the-application&#34;&gt;Testing the application&lt;/h2&gt;

&lt;p&gt;Remember the DNS we assigned to the Azure VM? In my case it was &lt;code&gt;http://ubuntu-docker-cloud.westeurope.cloudapp.azure.com/&lt;/code&gt;. Normally, the container should have started on port 80 (the default HTTP port) on this machine.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s try and access that exact URL:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/public-app.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At this point, you can create additional service and start containers on this machine, provided you open ports on the VM with the procedure described above.&lt;/p&gt;

&lt;h2 id=&#34;updating-the-application&#34;&gt;Updating the application&lt;/h2&gt;

&lt;p&gt;Because we setup the image based on the GitHub repository and we checked the &lt;code&gt;AUTOREDEPLOY&lt;/code&gt; option, every time we will push on the master branch of the repository, the entire system will update itself.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s slightly modify the application and push the modifications. This should trigger the auto build and auto redeploy of the container and without us doing anything, the modifications should be live.&lt;/p&gt;

&lt;p&gt;I just changed the message the application responds with and pushed the modifications to the master branch. This should trigger the build and redeploy of the container.&lt;/p&gt;

&lt;p&gt;You should see the new build in the &lt;code&gt;Recent Builds&lt;/code&gt; tab from the &lt;code&gt;Repositories&lt;/code&gt; page:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/recent-builds.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can also see all events in Slack:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/slack-build-events.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After the build and redeploy are successful, accessing the application should reflect the modifications:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/public-app-updated.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is basically how the entire process looks like. It is not production ready, as it does not have any testing workflow put in place and the application is rather simple.&lt;/p&gt;

&lt;p&gt;Real world scenarions would most certainly involve more containers, so composing and orchestrating containers, as well as testing.&lt;/p&gt;

&lt;p&gt;We will try to deal with these aspects in future articles, but for now we created a very simple CI/CD workflow using GitHub, Docker Cloud and an Azure VM.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>