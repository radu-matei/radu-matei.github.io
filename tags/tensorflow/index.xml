<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow on radu&#39;s blog</title>
    <link>https://radu-matei.com/tags/tensorflow/</link>
    <description>Recent content in tensorflow on radu&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>radu@matei.ai (Radu Matei)</managingEditor>
    <webMaster>radu@matei.ai (Radu Matei)</webMaster>
    <copyright>Radu Matei</copyright>
    <lastBuildDate>Sun, 18 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://radu-matei.com/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>TensorFlow inferencing using WebAssembly and WASI</title>
      <link>https://radu-matei.com/blog/tensorflow-inferencing-wasi/</link>
      <pubDate>Sun, 18 Oct 2020 00:00:00 +0000</pubDate>
      <author>radu@matei.ai (Radu Matei)</author>
      <guid>https://radu-matei.com/blog/tensorflow-inferencing-wasi/</guid>
      <description>In this article, we experiment with building a Rust program that performs image classification using the MobileNet V2 TensorFlow model, compile it to WebAssembly, and instantiate the module using two WebAssembly runtimes that use the WebAssembly System Interface (WASI), the native NodeJS WASI runtime, and Wasmtime. A special interest is given to writing model and image data into the moduleâ€™s linear memory, with implementations in both JavaScript and Rust. Finally, a simple prediction API is exemplified running on top of the Wasmtime runtime, and some limitations of this approach are discussed.</description>
    </item>
    
  </channel>
</rss>
